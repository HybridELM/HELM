{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f335f2c-d42e-41d9-b3f9-a0574c04dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"C:\\\\Users\\\\dnguy\\\\OneDrive\\\\Desktop\\\\0 Capstone\\\\Capstone\\\\Python\\\\list_data.json\") as json_file:\n",
    "    json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ead81b-8908-4242-bc2a-13bb55582d38",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# set gpu\u001b[39;00m\n\u001b[0;32m     12\u001b[0m physical_devices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mset_memory_growth(physical_devices[\u001b[39m0\u001b[39;49m], \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     16\u001b[0m error_log \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "##DEFINE FUNCTIONS\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# set gpu\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "start_time = time.time()\n",
    "error_log = []\n",
    "LSTM_Forecasts = []\n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    horizon = y_pred.shape[1]\n",
    "    numer = tf.abs(y_pred - y_true)\n",
    "    denom = tf.abs(y_pred) + tf.abs(y_true) + tf.keras.backend.epsilon()\n",
    "    return (200 / horizon) * tf.reduce_sum(numer / denom)\n",
    "\n",
    "def run_LSTM(ts, horizon, n_steps, cells, learning_rate, epochs, patience, min_delta, dropout_rate):\n",
    "    # Differencing the time series data\n",
    "    #diff_ts = difference(ts)\n",
    "   # diff_ts = np.array(diff_ts)\n",
    "    n = len(ts)\n",
    "    n_steps = n_steps\n",
    "    horizon = horizon\n",
    "    array_size = n - n_steps - horizon\n",
    "\n",
    "    x_train = np.zeros((array_size, n_steps, 1))\n",
    "    y_train = np.zeros((array_size, horizon))\n",
    "    x_test = np.zeros((1, n_steps, 1))\n",
    "    y_test = np.zeros((1, horizon))\n",
    "\n",
    "    for i in range(array_size):\n",
    "        x_train[i, :, :] = ts[i:(i+n_steps)].reshape(-1, 1)\n",
    "        y_train[i, :] = ts[(i+n_steps):(i+n_steps+horizon)]\n",
    "\n",
    "    y_test[0, :] = ts[(n-horizon):n]\n",
    "    x_test[0, :, :] = ts[(array_size):(n-horizon)].reshape(-1, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(cells, input_shape=(n_steps, 1), unroll=False))\n",
    "    # model.add(Dropout(dropout_rate))\n",
    "    # model.add(LSTM(cells, return_sequences=True))\n",
    "    # model.add(Dropout(dropout_rate))\n",
    "    # model.add(LSTM(cells, return_sequences=True))\n",
    "    # model.add(Dropout(dropout_rate))\n",
    "    # model.add(LSTM(cells))\n",
    "    model.add(Dense(horizon))\n",
    "\n",
    "    model.compile(loss=smape_loss, optimizer=Adam(learning_rate=learning_rate))\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=epochs, verbose=0, callbacks=[EarlyStopping(monitor='loss', patience=patience, min_delta=min_delta)])\n",
    "\n",
    "    preds= model.predict(x_test)\n",
    "\n",
    "    # De-differencing the forecasts\n",
    "    #preds = inverse_difference(ts[-n_steps:], preds_diff[0])\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d086a-dd73-423e-a333-fe2c474ec2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PARAMS\n",
    "\n",
    "horizon = 2\n",
    "n_steps = 25\n",
    "cells = 512\n",
    "#cells_2=512 #if you want this want, you have to add return_sequences=True to the first lstm layer and uncomment the second lstm layer\n",
    "#cells_3=512\n",
    "#cells_4=512\n",
    "learning_rate = 0.35\n",
    "epochs = 1000\n",
    "patience = 10\n",
    "min_delta = 0.01\n",
    "dropout_rate=0.071\n",
    "batch_size=32\n",
    "\n",
    "#\n",
    "which_series=range(0,1428) #change which series, via range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9fe2a-6a69-40eb-8d6b-0a6d80d60a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "###runs the lstm\n",
    "\n",
    "all_forecasts_1 = []\n",
    "\n",
    "for i in which_series:\n",
    "    ts = np.array(json_data[i]['target'])\n",
    "    series_forecasts = []\n",
    "    print(\"i am at \"+ str(i))\n",
    "    for _ in range(3):\n",
    "        with tf.device('/GPU:0'):\n",
    "            forecasts = run_LSTM(ts, horizon, n_steps, cells, learning_rate, epochs, patience, min_delta, dropout_rate)\n",
    "            series_forecasts.append(forecasts)\n",
    "            \n",
    "    series_forecasts = np.array(series_forecasts)\n",
    "    median_forecasts = np.median(series_forecasts, axis=0)\n",
    "    all_forecasts_1.append(median_forecasts)\n",
    "\n",
    "all_forecasts_1 = np.array(all_forecasts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f625b-ca6b-47c0-a056-80f931bfdeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This prints sMAPES for 1 horizon\n",
    "\n",
    "smape_horizon=18 #Change this for w/e horizon you are running in the lstm\n",
    "smapes_1=[]\n",
    "for i in range(0,all_forecasts_1.shape[0]):\n",
    "    temp = np.array(json_data[which_series[i]]['target'])\n",
    "    y_pred=all_forecasts_1[0].flatten()\n",
    "    y_true=temp[-smape_horizon:]\n",
    "    horizon = y_true.shape[0]\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    numer =  tf.abs(y_pred - y_true)\n",
    "    denom = tf.abs(y_pred) + tf.abs(y_true) + tf.keras.backend.epsilon()\n",
    "    smapes_1.append((200 / horizon) * (numer/denom).numpy().sum())\n",
    "smapes_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
